"""
Generate strokes for words that are marked as being compound nouns, e.g.
anteeksi=antaa;verb-kaivaa-av1
"""

from functools import partial
from multiprocessing import Pool
from typing import List, Tuple

from parsy import ParseError
from toolz import functoolz
from toolz.itertoolz import concat
from termcolor import cprint

import scripts.base_generation as g
from generators.compound_words import strokefy_compound_word

cores = 8

my_target_file = "../input_dictionaries/25_autogenerated_joukahainen_compound_nouns.json"

def compound_word(word):
    return "=" in word

def create_strokes_for_words(words_raw, ignore_words):
    def strokefy(word_info):
        try:
            return strokefy_compound_word(g.inflected_forms, word_info)
        except ParseError as e:
            cprint("Error strokefying word %s: %s" % (word_info, e), "green")

    strokes = functoolz.thread_last(words_raw,
                                    (filter, compound_word),
                                    (map, strokefy),
                                    (filter, lambda a: a is not None and a != []),
                                    # realize the lazy sequence
                                    list)
    print("Processed {} strokes.".format(len(words_raw)))
    return strokes

def main():
    (chunks, ignore_words) = g.wordlist_chunks(cores, my_target_file)

    with Pool(cores) as pool:
        # "map" step
        do_create = partial(create_strokes_for_words,
                            ignore_words=ignore_words)

        strokes = pool.map(do_create, chunks)

        # "reduce" step
        word_stroke_dict = g.flatten_dictify_matched(strokes)

        g.write_to_json_file(my_target_file, word_stroke_dict)
        return 0

if __name__ == '__main__':
    import sys
    sys.exit(main())
